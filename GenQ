from pyspark.sql.functions import lit

def get_prb_data(vendor, start_days, elptCoreDB, enodes=None, spark=None, markets=[]):
    """
    Fetch hourly PRB data for Ericsson, Samsung, or Nokia.

    :param vendor: Name of the vendor ('ericsson', 'samsung', 'nokia')
    :param start_days: Number of days to look back
    :param elptCoreDB: Database reference
    :param enodes: Optional list of ENODEB values to filter
    :param spark: Spark session
    :param markets: Optional list of market filters
    :return: Spark DataFrame with PRB data
    """
    days = str(start_days)
    
    # Mapping vendors to table names
    vendor_table_map = {
        "ericsson": "airwave_prb_per_branch_raw_v1",
        "samsung": "hourly_samsung_individual_prb_noise_raw_v2",
        "nokia": "hourly_nokia_prb_noise_raw_v2"
    }
    
    if vendor not in vendor_table_map:
        raise ValueError("Invalid vendor name! Choose from 'ericsson', 'samsung', or 'nokia'.")

    table_name = vendor_table_map[vendor]

    market_filter = ""
    if len(markets) > 0:
        market_filter = " AND market in ({})".format(",".join(f"'{m}'" for m in markets))

    # Base query (Ericsson has SECTORCARRIERREF, others do not)
    base_query = f"""
        SELECT *, {'SECTORCARRIERREF,' if vendor == 'ericsson' else ''} 
               SAFE.PARSE_DATE('%m/%d/%Y', day) AS parsed_date
        FROM `{elptCoreDB}.{table_name}`
        WHERE SAFE.PARSE_DATE('%m/%d/%Y', day) >= SAFE.PARSE_DATE('%Y-%m-%d', '{start_days}')
        AND trans_dt >= date_sub(SAFE.PARSE_DATE('%Y-%m-%d', '{start_days}'), INTERVAL {days} DAY)
        {market_filter}
    """

    if vendor == "ericsson":
        # Ensure SECTORCARRIERREF is present and not null
        base_query += " AND (SECTORCARRIERREF IS NOT NULL AND LENGTH(TRIM(SECTORCARRIERREF)) > 0)"

    if enodes:
        enode_filter = " AND TRIM(ENODEB) IN ({})".format(",".join(f"'{e}'" for e in enodes))
        query = base_query + enode_filter
    else:
        query = base_query

    prb_data = spark.read.format("bigquery").load(query)

    # If vendor is NOT Ericsson, add SECTORCARRIERREF with a default value
    if vendor in ["samsung", "nokia"]:
        prb_data = prb_data.withColumn("SECTORCARRIERREF", lit(1))

    return prb_data


new 
def get_prbdata_generic(vendor, start_days, days, elptCoreDB, markets, spark):
    from pyspark.sql.functions import col, lit, concat_ws
    import traceback

    try:
        # Table mapping per vendor
        table_map = {
            "Ericsson": "ericsson_hourly_prb_data",
            "Samsung": "samsung_hourly_prb_data",
            "Nokia": "nokia_hourly_prb_data"
        }

        table_name = table_map.get(vendor)
        if not table_name:
            raise ValueError("Unsupported vendor")

        market_filter = ""
        if markets:
            market_filter = " AND market in ({})".format(",".join(f"'{m}'" for m in markets))

        day_filter = " AND day != 'Total'" if vendor in ["Samsung", "Nokia"] else ""

        base_query = f"""
            SELECT *, {'SECTORCARRIERREF,' if vendor == 'Ericsson' else ''} 
                   SAFE.PARSE_DATE('%m/%d/%Y', day) AS parsed_date
            FROM `{elptCoreDB}.{table_name}`
            WHERE SAFE.PARSE_DATE('%m/%d/%Y', day) >= SAFE.PARSE_DATE('%Y-%m-%d', '{start_days}')
            AND trans_dt >= date_sub(SAFE.PARSE_DATE('%Y-%m-%d', '{start_days}'), INTERVAL {days} DAY)
            {market_filter}
            {day_filter}
        """

        print(f"Running query for {vendor}: {base_query}")
        df = spark.sql(base_query)

        # If SECTORCARRIERREF is not present (Samsung/Nokia), create it
        if 'SECTORCARRIERREF' not in df.columns:
            df = df.withColumn('SECTORCARRIERREF', concat_ws('_', col('eutrancell'), col('carrier')))

        # Ensure rfbranchrx column exists
        if 'rfbranchrx' not in df.columns:
            df = df.withColumn('rfbranchrx', lit(1))

        return df

    except Exception as e:
        print(f"Failed to fetch PRB data for {vendor}: {e}")
        traceback.print_exc()
        return None


new2

def get_prbdata_generic(vendor, start_days, days, elptCoreDB, markets, spark):
    from pyspark.sql.functions import col, lit, concat_ws
    import traceback

    try:
        # Table mapping per vendor
        table_map = {
            "Ericsson": "ericsson_hourly_prb_data",
            "Samsung": "samsung_hourly_prb_data",
            "Nokia": "nokia_hourly_prb_data"
        }

        table_name = table_map.get(vendor)
        if not table_name:
            raise ValueError("Unsupported vendor")

        market_filter = ""
        if markets:
            market_filter = " AND market in ({})".format(",".join(f"'{m}'" for m in markets))

        day_filter = " AND day != 'Total'" if vendor in ["Samsung", "Nokia"] else ""

        base_query = f"""
            SELECT *, {'SECTORCARRIERREF,' if vendor == 'Ericsson' else ''} 
                   SAFE.PARSE_DATE('%m/%d/%Y', day) AS parsed_date
            FROM `{elptCoreDB}.{table_name}`
            WHERE SAFE.PARSE_DATE('%m/%d/%Y', day) >= SAFE.PARSE_DATE('%Y-%m-%d', '{start_days}')
            AND trans_dt >= date_sub(SAFE.PARSE_DATE('%Y-%m-%d', '{start_days}'), INTERVAL {days} DAY)
            {market_filter}
            {day_filter}
        """

        print(f"Running query for {vendor}: {base_query}")
        df = spark.sql(base_query)

        # If SECTORCARRIERREF is not present (Samsung/Nokia), create it
        if 'SECTORCARRIERREF' not in df.columns:
            df = df.withColumn('SECTORCARRIERREF', concat_ws('_', col('eutrancell'), col('carrier')))

        # Ensure rfbranchrx column exists
        if 'rfbranchrx' not in df.columns:
            df = df.withColumn('rfbranchrx', lit(1))

        return df

    except Exception as e:
        print(f"Failed to fetch PRB data for {vendor}: {e}")
        traceback.print_exc()
        return None





