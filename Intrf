from pyspark.sql.functions import col, lit, when, concat_ws
import numpy as np
import traceback

def get_hot_sectors_sparkdf(vendor, startdt, enddt, coreDB, avgLevel, enodebs=None, markets=[], spark=None):
    """
    Unified function to process PRB data for Ericsson, Nokia, and Samsung with additional filtering conditions.
    
    Parameters:
        vendor (str): 'Ericsson', 'Nokia', or 'Samsung'
        startdt (str): Start date
        enddt (str): End date
        coreDB (str): Database name
        avgLevel (float): Threshold for high interference
        enodebs (list, optional): List of ENODEBs to filter
        markets (list): List of markets
        spark (SparkSession): Spark session
    
    Returns:
        prb_data (DataFrame): Processed PRB data
        all_prb_stats (DataFrame): PRB statistics
    """
    prb_data = None  # Initialize dataset
    
    vendor_map = {
        "Ericsson": {"prefix": "eric_avg_iot_prb", "table": "vz-1-nd1pr-0.vzn_nd1_elpt_core_views", "condition": lambda col_val: when(col(col_val) < -30, None)},
        "Nokia": {"prefix": "nok_avg_iot_prb", "table": "vz-1-nd1pr-0.vzn_nd1_alpt_core_views", "condition": lambda col_val: when((col(col_val) < -25) | (col(col_val) > 50), None)},
        "Samsung": {"prefix": "sea_avg_iot_prb", "table": "vz-1-nd1pr-0.vzn_nd1_alpt_core_views", "condition": lambda col_val: when((col(col_val) < -20) | (col(col_val) > 45), None)}
    }
    
    if vendor not in vendor_map:
        raise ValueError("Invalid vendor. Choose from 'Ericsson', 'Nokia', or 'Samsung'.")
    
    prefix = vendor_map[vendor]["prefix"]
    table = vendor_map[vendor]["table"]
    invalid_condition = vendor_map[vendor]["condition"]
    
    try:
        print(f"Fetching {vendor} PRB data with additional conditions...")
        
        # Fetch PRB data
        prb_data = get_prb_data(startdt, enddt, table, coreDB, spark, markets)
        prb_data = prb_data.drop_duplicates()
        
        if enodebs:
            prb_data = prb_data.filter(col("ENODEB").isin(enodebs))
        
        # Ensure SECTORCARRIERREF is not NULL or empty
        prb_data = prb_data.filter((col("SECTORCARRIERREF").isNotNull()) & (col("SECTORCARRIERREF").rlike("\\S")))
        
        # Handle invalid values
        prb_cols = [c for c in prb_data.columns if prefix in c]
        prb_data = prb_data.select([invalid_condition(c).otherwise(col(c)).alias(c) if c in prb_cols else col(c) for c in prb_data.columns])
        
        # Rename and process columns
        prb_data = prb_data.withColumnRenamed("enodeb", "ENODEB").withColumnRenamed("eutrancell", "EUTRANCELL").withColumnRenamed("carrier", "CARRIER")
        prb_data = prb_data.withColumn("SECTORCARRIERREF", concat_ws("_", prb_data.EUTRANCELL, prb_data.CARRIER))
        
        # Aggregation
        group_cols = ["ENODEB", "SECTORCARRIERREF"]
        avg_prb = prb_data.groupBy(group_cols).apply(branch_average)
        std_prb = prb_data.groupBy(group_cols).apply(branch_stdev_all_dbm)
        all_prb_stats = avg_prb.join(std_prb, on=group_cols)
        
        # Filter high-interference sectors
        prb_data_avg = prb_data.join(all_prb_stats, on=group_cols, how="left_anti")
        top_interferers = prb_data_avg.filter(col("WEIGHTEDAVGRADIOINTERFERENCE") >= avgLevel)
        
        print(f"Found {top_interferers.count()} sectors with high interference.")
        
        prb_data = prb_data.join(top_interferers, on=["ENODEB", "SECTORCARRIERREF"])
        
    except Exception as e:
        print(f"-ERROR- Could not extract {vendor} PRB data with error: {e}")
        traceback.print_exc()
    
    return prb_data, all_prb_stats
